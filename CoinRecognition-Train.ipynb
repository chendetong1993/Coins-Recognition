{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.regularizers as R\n",
    "import tensorflow.keras.backend as B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print (tf.__version__)\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"E:/Documents/Others/Desktop/WIn10/Desktop/coins datasets/coins/data/train\"\n",
    "test_dir = \"E:/Documents/Others/Desktop/WIn10/Desktop/coins datasets/coins/data/test\"\n",
    "\n",
    "train_img_paths = [str(x).replace(\"\\\\\", \"/\") for x in tqdm(pathlib.Path(train_dir).rglob('*.*'))]\n",
    "test_img_paths = [str(x).replace(\"\\\\\", \"/\") for x in tqdm(pathlib.Path(test_dir).rglob('*.*'))]\n",
    "\n",
    "print(len(train_img_paths), len(test_img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_shape = (224, 224, 3)\n",
    "num_classes = 211\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesExtractor():\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        pass\n",
    "    \n",
    "    @tf.function\n",
    "    def _img_read_tf(self, file_path):\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        label = tf.one_hot(tf.strings.to_number(tf.strings.split(file_path, '/')[-2], tf.int32) - 1, num_classes)\n",
    "        return img, label\n",
    "    \n",
    "    @tf.function\n",
    "    def _img_resize_tf(self, img, label):\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        img = tf.image.resize(img, image_shape[:2])\n",
    "        return img, label\n",
    "    \n",
    "    def img_batch(self, file_paths, shuffle=0):\n",
    "        AUTO = tf.data.experimental.AUTOTUNE\n",
    "        res = tf.data.Dataset.from_tensor_slices(file_paths)\n",
    "        if shuffle > 0:\n",
    "            res = res.shuffle(shuffle)\n",
    "        res = res.map(self._img_read_tf, num_parallel_calls=AUTO)\n",
    "        res = res.map(lambda x, y: self._img_resize_tf(x, y), num_parallel_calls=AUTO)\n",
    "        res = res.batch(batch_size) #.prefetch(AUTO)\n",
    "        return res\n",
    "    \n",
    "    def img_iter(self, file_paths):\n",
    "        AUTO = tf.data.experimental.AUTOTUNE\n",
    "        res = tf.data.Dataset.from_tensor_slices(file_paths)\n",
    "        res = res.map(self._img_read_tf, num_parallel_calls=AUTO)\n",
    "        res = res.batch(1) #.prefetch(AUTO)\n",
    "        return res\n",
    "        \n",
    "images_extractor = ImagesExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_batch_generator = images_extractor.img_batch(train_img_paths, 2048)\n",
    "#train_img_iter_generator = images_extractor.img_iter(train_img_paths)\n",
    "\n",
    "test_img_batch_generator = images_extractor.img_batch(test_img_paths)\n",
    "#test_img_iter_generator = images_extractor.img_iter(test_img_paths)\n",
    "\n",
    "\n",
    "sample_img_paths = ['E:/Documents/Others/Desktop/WIn10/Desktop/coins datasets/coins/data/train/37/2020-10-04_122500.png', \n",
    "                    'E:/Documents/Others/Desktop/WIn10/Desktop/coins datasets/coins/data/train/37/2020-10-04_122447.png',\n",
    "                    'E:/Documents/Others/Desktop/WIn10/Desktop/coins datasets/coins/data/train/36/2020-10-04_121511.png', \n",
    "                    'E:/Documents/Others/Desktop/WIn10/Desktop/coins datasets/coins/data/train/36/2020-10-04_121528.png']\n",
    "sample_img_batch_generator = images_extractor.img_batch(sample_img_paths)\n",
    "#sample_img_iter_generator = images_extractor.img_iter(sample_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "@tf.function\n",
    "def aug_grid_mask(batch_tuple, d1=128, d2=224, ratio=0.6):\n",
    "    img_batch, label_batch = batch_tuple\n",
    "    batch_size, img_h, img_w = tf.shape(img_batch)[0], img_batch.shape[1], img_batch.shape[2]\n",
    "    d = tf.random.uniform(shape=[batch_size, 1], minval=d1, maxval=d2, dtype=tf.int32) # (Batch Size, 1)\n",
    "    d_f32 = tf.cast(d, tf.float32) # (Batch Size, 1)\n",
    "    y_range = tf.reshape(tf.range(img_h), (1, -1)) + tf.cast(tf.random.uniform(shape=[batch_size, 1], dtype=tf.float32) * d_f32 - 1, tf.int32)# (Batch Size, IMG_H)\n",
    "    x_range = tf.reshape(tf.range(img_w), (1, -1)) + tf.cast(tf.random.uniform(shape=[batch_size, 1], dtype=tf.float32) * d_f32 - 1, tf.int32) # (Batch Size, IMG_W)\n",
    "    y_range = tf.expand_dims(tf.cast(y_range % d, tf.float32) / d_f32 >= ratio, axis=2) # (Batch Size, IMG_H, 1)\n",
    "    x_range = tf.expand_dims(tf.cast(x_range % d, tf.float32) / d_f32 >= ratio, axis=1) # (Batch Size, 1, IMG_W)\n",
    "    mask = tf.expand_dims(tf.math.logical_and(y_range, x_range) == False, axis=-1) # (Batch Size, IMG_H, IMG_W, 1)\n",
    "    img_batch =  tf.where(mask, img_batch, 0)\n",
    "    return (img_batch, label_batch)\n",
    "\n",
    "@tf.function\n",
    "def aug_affine(batch_tuple, rotation=360, shear=15, zoom=[0.7, 1.1], shift=[-16, 16], flip=3):\n",
    "    img_batch, label_batch = batch_tuple\n",
    "    batch_shape, batch_size, img_h, img_w = tf.shape(img_batch), tf.shape(img_batch)[0], img_batch.shape[1], img_batch.shape[2]\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "    # CONVERT\n",
    "    one = tf.ones([batch_size, 1], dtype='float32') # (Batch Size, 1)\n",
    "    zero = tf.zeros([batch_size, 1], dtype='float32') # (Batch Size, 1)\n",
    "    m_list = []\n",
    "    if rotation != 0:\n",
    "        rotation = math.pi * tf.random.uniform(shape=[batch_size, 1], minval=-rotation, maxval=rotation) / 180. # (Batch Size, 1)\n",
    "        c1 = tf.math.cos(rotation) # (Batch Size, 1)\n",
    "        s1 = tf.math.sin(rotation) # (Batch Size, 1)\n",
    "        rotation_matrix = tf.concat([c1, s1, zero, -s1, c1, zero, zero, zero, one], axis=-1) # (Batch Size, 9)\n",
    "        rotation_matrix = tf.reshape(rotation_matrix, [-1, 3, 3]) # (Batch Size, 3, 3)\n",
    "        #m = rotation_matrix if (m is None) else B.batch_dot(m, rotation_matrix)\n",
    "        m_list.append(rotation_matrix)\n",
    "    if shear != 0:\n",
    "        shear = math.pi * tf.random.uniform(shape=[batch_size, 1], minval=-shear, maxval=shear) / 180.       # (Batch Size, 1)\n",
    "        c2 = tf.math.cos(shear) # (Batch Size, 1)\n",
    "        s2 = tf.math.sin(shear) # (Batch Size, 1)\n",
    "        shear_matrix = tf.concat([one, s2, zero, zero, c2, zero, zero, zero, one], axis=-1) # (Batch Size, 9)\n",
    "        shear_matrix = tf.reshape(shear_matrix, [-1, 3, 3]) # (Batch Size, 3, 3)\n",
    "        #m = shear_matrix if (m is None) else B.batch_dot(m, shear_matrix)\n",
    "        m_list.append(shear_matrix)\n",
    "    if zoom[0] != 1 or zoom[1] != 1:\n",
    "        width_zoom = tf.random.uniform(shape=[batch_size, 1], minval=zoom[0], maxval=zoom[1]) # (Batch Size, 1)\n",
    "        height_zoom = tf.random.uniform(shape=[batch_size, 1], minval=zoom[0], maxval=zoom[1]) # (Batch Size, 1)\n",
    "        zoom_matrix = tf.concat([one / height_zoom, zero, zero, zero, one / width_zoom, zero, zero, zero, one], axis=-1) # (Batch Size, 9)\n",
    "        zoom_matrix = tf.reshape(zoom_matrix, [-1, 3, 3]) # (Batch Size, 3, 3)\n",
    "        m_list.append(zoom_matrix)\n",
    "    if shift[0] != 0 or shift[1] != 0:\n",
    "        height_shift = tf.random.uniform(shape=[batch_size, 1], minval=shift[0], maxval=shift[1]) # (Batch Size, 1)\n",
    "        width_shift = tf.random.uniform(shape=[batch_size, 1], minval=shift[0], maxval=shift[1]) # (Batch Size, 1)\n",
    "        shift_matrix = tf.concat([one, zero, height_shift, zero, one, width_shift, zero, zero, one], axis=-1)\n",
    "        shift_matrix = tf.reshape(shift_matrix, [-1, 3, 3]) # (Batch Size, 3, 3)\n",
    "        m_list.append(shift_matrix)\n",
    "    if flip != 0:\n",
    "        # 1: left_right 2: up_down 3: both\n",
    "        flip_y = tf.where(tf.random.uniform(shape=[batch_size, 1]) >= (0.5 if (flip == 1 or flip == 3) else 0), 1., -1.)\n",
    "        flip_x = tf.where(tf.random.uniform(shape=[batch_size, 1]) >= (0.5 if (flip == 2 or flip == 3) else 0), 1., -1.)\n",
    "        flip_matrix = tf.concat([flip_y, zero, zero, zero, flip_x, zero, zero, zero, one], axis=-1)\n",
    "        flip_matrix = tf.reshape(flip_matrix, [-1, 3, 3]) # (Batch Size, 3, 3)\n",
    "        #m = flip_matrix if (m is None) else B.batch_dot(m, flip_matrix)\n",
    "        m_list.append(flip_matrix)\n",
    "    if len(m_list) > 0:\n",
    "        # MERGE MATRIX\n",
    "        m_list = tf.unstack(tf.random.shuffle(tf.stack(m_list, axis=0)), axis=0) # List of (Batch Size, 3, 3)\n",
    "        m = reduce((lambda x, y: B.batch_dot(x, y)), m_list)\n",
    "        # LIST DESTINATION PIXEL INDICES\n",
    "        \n",
    "        x, y = tf.meshgrid(tf.range(img_w//2, -img_w//2, -1), tf.range(-img_h//2, img_h//2, 1)) # (Img_h, Img_w)\n",
    "        x, y = tf.reshape(x, [-1]), tf.reshape(y, [-1])\n",
    "\n",
    "        z = tf.ones([img_h * img_w], tf.int32) # (IMG_H * IMG_W)\n",
    "        idx = tf.stack([x, y, z])              # (3, IMG_H * IMG_W)\n",
    "        idx = tf.expand_dims(idx, axis=0)  # (1, 3, IMG_H * IMG_W)\n",
    "\n",
    "        # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "        idx = tf.cast(B.batch_dot(m, tf.cast(idx, tf.float32)), tf.int32) # (Batch Size, 3, IMG_H * IMG_W)\n",
    "        x_idx, y_idx = idx[:,0,:], idx[:,1,:]\n",
    "        x_idx_valid = tf.math.logical_and(-img_w//2 + img_w%2 + 1 <= x_idx, x_idx <= img_w//2) # (Batch Size, IMG_H * IMG_W)\n",
    "        y_idx_valid = tf.math.logical_and(-img_h//2 + img_h%2 + 1 <= y_idx, y_idx <= img_h//2) # (Batch Size, IMG_H * IMG_W)\n",
    "        idx_valid = tf.math.logical_and(x_idx_valid, y_idx_valid) # # (Batch Size, IMG_H * IMG_W)\n",
    "        x_idx = tf.where(x_idx_valid, x_idx, 0)\n",
    "        y_idx = tf.where(y_idx_valid, y_idx, 0)\n",
    "        # FIND ORIGIN PIXEL VALUES           \n",
    "        idx = tf.stack([img_h//2-1+y_idx, img_w//2-x_idx],axis=-1) # (Batch Size, IMG_H * IMG_W, 2)\n",
    "        img_batch = tf.gather_nd(img_batch, idx, batch_dims=1) # (Batch Size, IMG_H * IMG_W, 3)\n",
    "        img_batch = tf.where(tf.expand_dims(idx_valid, axis=-1), img_batch, 0)\n",
    "        img_batch = tf.reshape(img_batch, batch_shape)\n",
    "    return (img_batch, label_batch)\n",
    "\n",
    "@tf.function\n",
    "def aug_color(batch_tuple, gaussian_s=0.01, hue_s=0.00, bright_s=0.1):\n",
    "    img_batch, label_batch = batch_tuple\n",
    "    \n",
    "    if gaussian_s > 0:\n",
    "        img_batch = img_batch + (gaussian_s * tf.random.normal(tf.shape(img_batch), mean=0.0, stddev=1., dtype=tf.float32))\n",
    "        img_batch = tf.clip_by_value(img_batch, 0., 1.)\n",
    "    \n",
    "    if hue_s > 0:\n",
    "        img_batch = tf.image.random_hue(img_batch, hue_s)\n",
    "        img_batch = tf.clip_by_value(img_batch, 0., 1.)\n",
    "    \n",
    "    if bright_s > 0:\n",
    "        img_batch = tf.image.random_brightness(img_batch, bright_s)\n",
    "        img_batch = tf.clip_by_value(img_batch, 0., 1.)\n",
    "    return (img_batch, label_batch)\n",
    "\n",
    "@tf.function\n",
    "def aug_mix(batch_tuple1, batch_tuple2, p):\n",
    "    (img_batch1, label_batch1), (img_batch2, label_batch2) = batch_tuple1, batch_tuple2\n",
    "    p = tf.random.uniform(shape=[tf.shape(img_batch1)[0]], minval=0, maxval=1, dtype=tf.float32) <= p\n",
    "    img_batch = tf.where(tf.reshape(p, (-1, 1, 1, 1)), img_batch1, img_batch2)\n",
    "    label_batch = tf.where(tf.reshape(p, (-1, 1)), label_batch1, label_batch2)\n",
    "    return (img_batch, label_batch)\n",
    "    \n",
    "    \n",
    "@tf.function\n",
    "def datasets_augumentation(img_batch, label_batch):\n",
    "    batch_tuple = (img_batch, label_batch)\n",
    "    # Color\n",
    "    #batch_tuple = aug_mix(aug_color(batch_tuple), batch_tuple, 0.7)\n",
    "\n",
    "    # Grid Mask\n",
    "    batch_tuple = aug_mix(aug_grid_mask(batch_tuple), batch_tuple, 0.7)\n",
    "\n",
    "    # Affine \n",
    "    batch_tuple = aug_affine(batch_tuple)\n",
    "\n",
    "    img_batch, label_batch = batch_tuple\n",
    "    return img_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "train_datasets_format = train_img_batch_generator.map(datasets_augumentation, num_parallel_calls=AUTO).prefetch(AUTO)\n",
    "test_datasets_format = test_img_batch_generator.prefetch(AUTO)\n",
    "sample_datasets_format = sample_img_batch_generator.prefetch(AUTO)\n",
    "\n",
    "for x, y_true in train_datasets_format:\n",
    "    for i in range(1):\n",
    "        plt.title(np.argmax(y_true[i]))\n",
    "        plt.imshow(x[i])\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineAnnealingWithWarmup(epochIdx):\n",
    "    aMin, aMax = 1e-5, 1e-3\n",
    "    warmupEpochs, stagnateEpochs, cosAnnealingEpochs = 10, 0, 100\n",
    "    epochIdx = epochIdx % (warmupEpochs + stagnateEpochs + cosAnnealingEpochs)\n",
    "    if(epochIdx < warmupEpochs):\n",
    "        return aMin + (aMax - aMin) / (warmupEpochs - 1) * epochIdx\n",
    "    else:\n",
    "        epochIdx -= warmupEpochs\n",
    "    if(epochIdx < stagnateEpochs):\n",
    "        return aMax\n",
    "    else:\n",
    "        epochIdx -= stagnateEpochs\n",
    "    return aMin + 0.5 * (aMax - aMin) * (1 + math.cos((epochIdx + 1) / (cosAnnealingEpochs + 1) * math.pi))\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=2, factor=0.5, mode='auto')\n",
    "#lr_schedule = tf.keras.callbacks.LearningRateScheduler(tf.keras.experimental.CosineDecayRestarts(5e-5, 10), verbose=1)\n",
    "#lr_schedule = tf.keras.callbacks.LearningRateScheduler(cosineAnnealingWithWarmup, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineLayer(L.Layer):\n",
    "    def __init__(self, n_classes=num_classes, regularizer=None, **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.regularizer = R.get(regularizer)\n",
    "\n",
    "    def build(self, input_shape): \n",
    "        super().build(input_shape)\n",
    "        # tf.constant_initializer(embedding_parms)\n",
    "        # initializer='glorot_uniform'\n",
    "        channel_cnt = 1\n",
    "        self.W = self.add_weight(name='W', shape=(channel_cnt, input_shape[-1], self.n_classes), initializer='glorot_uniform', trainable=True, regularizer=self.regularizer)\n",
    "        \n",
    "    def call(self, x):\n",
    "        # normalize feature\n",
    "        x = tf.nn.l2_normalize(x, axis=1) # (Batch Size, Embedding_Dims)\n",
    "        # normalize weights\n",
    "        W = tf.nn.l2_normalize(self.W, axis=1) # (2, Embedding_Dims, Num_Class)\n",
    "        \n",
    "        logits = tf.map_fn(lambda w: tf.matmul(x, w), W)\n",
    "        logits = tf.math.reduce_max(logits, axis=0)\n",
    "        #x = tf.math.reduce_max(x, axis = 1)\n",
    "        #W = tf.math.reduce_max(W, axis = 1)\n",
    "        \n",
    "        # a·b = |a|×|b|×cos<a,b> => cos<a,b> = (a/|a|)·(b/|b|)\n",
    "        #logits = tf.matmul(x, W) # (None, 512) (512, 10, 2) (None, 10)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationMetric(y_true, y_pred):\n",
    "    # y_pred = tf.nn.softmax(y_pred)  # (Batch Size, 10)\n",
    "    y_pred_idxs = tf.cast(tf.math.argmax(y_pred, -1), tf.int32) # (Batch Size)\n",
    "    y_true_idxs = tf.cast(tf.math.argmax(y_true, -1), tf.int32) # (Batch Size)\n",
    "    # print(y_pred_idxs, y_pred_score, y_true)\n",
    "    \n",
    "    return tf.reduce_sum(tf.cast(y_pred_idxs == y_true_idxs, tf.float32)) / (tf.cast(tf.shape(y_pred_idxs)[0], tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ArcFaceLoss(m=0.50, s=30.0):\n",
    "    def LossFunc(y_true, y_pred):\n",
    "        theta = tf.acos(tf.clip_by_value(y_pred, -0.999999, 0.999999))\n",
    "        y_pred_mod = tf.cos(tf.clip_by_value(theta + m, 0, np.pi))\n",
    "        #\n",
    "        y_pred = ((y_true) * y_pred_mod + (1 - y_true) * y_pred) * s\n",
    "\n",
    "        loss = losses.CategoricalCrossentropy(from_logits=True, reduction=losses.Reduction.NONE)(y_true, y_pred)\n",
    "        return loss\n",
    "    return LossFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CircleLoss(margin = 0.25, gamma=256):\n",
    "    def LossFunc(y_true, y_pred):\n",
    "        O_p = 1 + margin\n",
    "        O_n = - margin\n",
    "        Delta_p = 1 - margin\n",
    "        Delta_n = margin\n",
    "\n",
    "        alpha_p = tf.nn.relu(O_p - tf.stop_gradient(y_pred))\n",
    "        alpha_n = tf.nn.relu(tf.stop_gradient(y_pred) - O_n)\n",
    "\n",
    "        y_pred = ((y_true) * (alpha_p * (y_pred - Delta_p)) + (1 - y_true) * (alpha_n * (y_pred - Delta_n))) * gamma\n",
    "\n",
    "        # Weighted Loss\n",
    "        loss = losses.CategoricalCrossentropy(from_logits=True, reduction=losses.Reduction.NONE)(y_true, y_pred)\n",
    "        return loss\n",
    "    return LossFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rgb2GrayLayer(L.Layer):\n",
    "    def __init__(self, **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        pass\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.image.rgb_to_grayscale(x)\n",
    "        x = tf.repeat(x, 3, axis=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetricLearningType = \"Circle\"\n",
    "MetricLearningLayer = { \"ArcFace\": CosineLayer, \"Circle\": CosineLayer }[MetricLearningType]\n",
    "MetricLearningLoss = { \"ArcFace\": ArcFaceLoss, \"Circle\": CircleLoss }[MetricLearningType]()\n",
    "MetricLearningMetric = ClassificationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input = Input(shape=image_shape, name='Input')\n",
    "    x = input\n",
    "    #x = Rgb2GrayLayer(name='Rgb2Gray')(input)\n",
    "    #backbone = efn.EfficientNetB0(input_shape=image_shape, include_top=False, weights='imagenet')\n",
    "    backbone = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=image_shape, include_top=False, weights='imagenet')\n",
    "    for layer in backbone.layers:\n",
    "        layer.trainable = True  # trainable has to be false in order to freeze the layers\n",
    "\n",
    "    x = backbone(x)\n",
    "    x = L.GlobalAveragePooling2D(name='Gap')(x)\n",
    "    #x = L.BatchNormalization(name='BN0')(x)\n",
    "    \n",
    "    x = L.Dropout(0.75, name=\"Dropout\")(x)\n",
    "    x = L.Dense(256, name='Dense', activation=None)(x)\n",
    "    # x = L.Dropout(0.8, name=\"Dropout\")(x)\n",
    "    #x = L.BatchNormalization(name='BN1')(x)\n",
    "    x = MetricLearningLayer(name='Final')(x)\n",
    "    output = x\n",
    "\n",
    "    model = Model(input, output, name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(1e-3), loss = MetricLearningLoss, metrics=MetricLearningMetric)\n",
    "    #model.load_weights('***', by_name=True, skip_mismatch=True)\n",
    "    model.summary()\n",
    "    return model\n",
    "    \n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeout_check(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss, accuracy = self.model.evaluate(test_datasets_format) #, steps=4)\n",
    "        self.model.save_weights(\"model_{:.0f}_{:.4f}_{:.4f}_{:.5f}.h5\".format(float(epoch + 1), loss, accuracy, self.model.optimizer.learning_rate.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [lr_schedule, timeout_check()]\n",
    "#model.load_weights(\"C:\\\\Users\\\\chend\\\\model_99_52.3398_0.7924_0.00001.h5\")\n",
    "model.fit(train_datasets_format, epochs=epochs, callbacks=callbacks_list) #, steps_per_epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2NormLayer(L.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        pass\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, **kwargs):\n",
    "        inputs = tf.math.l2_normalize(inputs, axis=1)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MetricLearningModel(name=None):\n",
    "    input = Input(shape=image_shape, name='Input')\n",
    "    #backbone = efn.EfficientNetB0(input_shape=image_shape, include_top=False, weights='imagenet')\n",
    "    backbone = tf.keras.applications.MobileNetV2(input_shape=image_shape, include_top=False, weights='imagenet')\n",
    "    x = backbone(input)\n",
    "    x = L.GlobalAveragePooling2D(name='Gap')(x)\n",
    "\n",
    "    x = L.Dense(256, name='Dense', activation=None)(x)\n",
    "    x = L2NormLayer(name=\"L2\")(x)\n",
    "    output = x\n",
    "    model = Model(input, output, name=name)\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalFeatureExtractor():\n",
    "    def __init__(self, model):\n",
    "        self.model = MetricLearningModel(\"Backbone\")\n",
    "        #model.load_weights(\"C:\\\\Users\\\\chend\\\\model_99_52.3398_0.7924_0.00001.h5\", by_name=True, skip_mismatch=True)\n",
    "        self.model.summary()\n",
    "    \n",
    "    def extract_features(self, img_generator, steps=None):\n",
    "        return self.model.predict(img_generator, verbose=1, steps=steps)\n",
    "\n",
    "    @tf.function\n",
    "    def _cos_similarity_iter(self, embedding_target, embedding_sources, k):\n",
    "        distances = tf.matmul(embedding_sources, tf.expand_dims(embedding_target, axis=-1))[:,0] # (#embedding_sources)\n",
    "        nearset_distances, nearest_idxs = tf.math.top_k(distances, k=k, sorted=True)\n",
    "        nearset_distances, nearest_idxs = tf.cast(nearset_distances, tf.float32), tf.cast(nearest_idxs, tf.float32)\n",
    "        return tf.stack([nearest_idxs, nearset_distances], axis=1) #(3, 2)\n",
    "    \n",
    "    @tf.function\n",
    "    def cos_similarity(self, embedding_targets, embedding_sources, k):\n",
    "        return tf.map_fn(lambda x: self._cos_similarity_iter(x, embedding_sources, k), embedding_targets, parallel_iterations=8) #(?, 3, 2)\n",
    "    \n",
    "\n",
    "global_feature_extractor = GlobalFeatureExtractor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_feature_extractor.extract_features(sample_img_batch_generator)\n",
    "sample_img_features = global_feature_extractor.extract_features(sample_img_batch_generator, 1)\n",
    "print(global_feature_extractor.cos_similarity(sample_img_features, sample_img_features, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
